# 开发离线本地知识库产品 (Go + llama.cpp + SQLite)

本计划旨在实现一个跨平台、无依赖、一键安装的离线知识库产品。核心采用 Go 语言开发，嵌入 llama.cpp 推理引擎，使用 SQLite 存储数据，并提供 Web UI 交互。

## 阶段一：核心架构与功能实现 (MVP)

### 1. 项目初始化与架构设计

* **目录结构**：

  * `cmd/server`: 主程序入口。

  * `internal/core`: 核心逻辑。

  * `internal/db`: SQLite 数据库操作。

  * `internal/llm`: LLM 推理接口 (定义接口与实现)。

  * `web/`: 前端资源 (HTML/CSS/JS)。

* **依赖管理**：使用 `go mod` 管理依赖 (Gin, GORM, go-llama.cpp)。

### 2. 核心模块开发

* **推理引擎集成 (`internal/llm`)**：

  * 定义 `LLMEngine` 接口。

  * 实现 `LlamaCppEngine`：使用 `go-skynet/go-llama.cpp` 通过 CGO 调用底层模型。

  * **注意**：为了确保在当前开发环境可演示，将提供一个 `MockEngine` 作为备选，方便调试前端与业务逻辑。

* **数据存储 (`internal/db`)**：

  * 集成 SQLite，实现单文件数据库。

  * 设计表结构：存储会话历史、知识库条目。

* **Web 服务 (`internal/web`)**：

  * 使用 Gin 框架提供 REST API。

  * 使用 `go:embed` 将前端 HTML/CSS/JS 打包进单一二进制文件。

  * 实现自动打开浏览器逻辑。

### 3. 前端界面开发

* 开发简洁的 Chat UI (Vue/TailwindCSS)。

* 实现与后端 API 的流式交互 (Server-Sent Events 或 WebSocket)。

## 阶段二：跨平台编译与打包

### 1. Windows 平台支持

* **编译脚本**：编写 `build_windows.bat`。

* **资源处理**：确保图标和元数据嵌入 exe。

* **隐藏控制台**：使用 `-ldflags -H=windowsgui` 隐藏命令行窗口。

### 2. macOS 平台支持

* **应用打包**：编写 `build_mac.sh`，生成标准的 `.app` 目录结构 (`Contents/MacOS`, `Contents/Resources`)。

* **权限处理**：处理 macOS 的各种权限请求（如需要）。

## 阶段三：安装包制作与分发

### 1. Windows 安装包 (NSIS)

* 编写 NSIS 脚本 (`installer.nsi`)：

  * 实现一键安装。

  * 自定义安装路径。

  * 创建桌面快捷方式。

  * 自动复制 U 盘中的模型文件到安装目录。

### 2. macOS 安装镜像 (DMG)

* 提供创建 DMG 的脚本或说明：

  * 创建拖拽式安装界面 (`/Applications` 软链接)。

### 3. 启动与模型管理

* **启动逻辑**：程序启动时自动检测当前目录或用户数据目录下的模型文件。

* **内存适配**：简单的系统内存检测逻辑，推荐加载不同量化的模型。

***

**下一步操作**：

1. 初始化 Go 项目。
2. 创建基础目录结构和核心代码框架。
3. 实现 SQLite 和 Web Server 基础功能。

