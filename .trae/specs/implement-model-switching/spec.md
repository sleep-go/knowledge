# 实现模型切换规格说明

## 背景
用户目前无法在不重启应用的情况下切换不同的 LLM 模型。实现运行时模型切换允许用户根据当前任务动态选择最佳模型，从而提高灵活性和用户体验。

## 变更内容
- 更新 `Engine` 接口以支持模型切换。
- 在 `LlamaEngine` 中实现 `SwitchModel`，确保线程安全。
- 添加列出 `models/` 目录下可用 `.gguf` 模型的功能。
- 添加 API 端点以列出和选择模型。

## 影响
- **受影响的 Spec**: 无。
- **受影响的代码**:
  - `internal/llm/engine.go`: 接口更新。
  - `internal/llm/llama.go`: 切换逻辑实现。
  - `internal/server/router.go`: 新的 API 路由。

## 新增需求

### 需求：模型管理 API
系统应提供 HTTP API 来列出和切换模型。

#### 场景：列出模型
- **当** 客户端请求 `GET /api/models`
- **则** 返回配置的模型目录中可用的 `.gguf` 文件列表。

#### 场景：切换模型
- **当** 客户端请求 `POST /api/models/select` 并提供有效的模型文件名
- **则** 系统卸载当前模型，加载新模型，并返回成功。
- **如果** 加载失败，返回错误消息。

### 需求：线程安全切换
系统应确保模型切换不会导致正在进行的聊天会话崩溃。
- **当** 在聊天进行时请求切换
- **则** 切换操作应等待聊天结束（或阻塞新聊天直到切换完成）。*注：为简单起见，我们将使用互斥锁在切换期间锁定引擎。*
